

### "Aaron Peikert" [00:04:37.799-00:04:41.116]
But, um, so.
Today, the agenda is pretty short. Um, so just a quick report from the equity thing. Um, the equity thing was about academic.
Housekeeping stuff, uh, which is more affecting woman. Um, and that is already the summary of.
1, and a half hour meeting.
Mostly, yes, um, so academic housekeeping is stuff that everyone agrees should be done, but no, 1 wants to do. Um, and this is predominantly, uh, affecting woman and.
Since we have a very low proportion of women, um, I can only think of a couple of occurrences where this might have happened. I think the most significant 1 was maybe the scientific advisory board meeting that was done by Leoni, uh, where we had exactly the situation of.
Okay, we have to do this and someone has to be, um.
Has to volunteer and that this then usually falls to a woman. Um, yeah, but unfortunately there wasn't, uh, much more than just the simple fact. Um, and not much recommendations on what you can do about it. So, I think the only.
Thing that we can do about it is be aware of this of this bias.
Then, um, you all have to call me now. Dr Aaron that is for 2 reasons. 1st. We, we smashed the junior researchers at pool. I think the, the main reasons, and the 2nd is a homeless University obviously 1 of the title, it's.
Um, then, um, 1 of the papers, I hope, uh, Max, you have time this week to finalize this and address. I added.
1, further paper, they just had to discuss and then I just found after already finalizing the submission, but I will send you the, the, it's done with everything so that you can see what changed. But I almost accepted all suggestions except of a couple of cases where the.
It wasn't complete or something. Um, but thank you very much for being so careful about reading, rereading everything because I know that this takes.
Quite a bit of time um, and that is yeah, it's it's Super valuable to see someone who's going so detailed about everything and thinking oh, is this the right route here? And, uh, so I really appreciate that. Um.
Then Naftali has.
It's coming, I added, uh, when he will be a way, thank you, Andres, for putting it into the calendar. Um, when he is generally here.
And there was 1 further idea for this.
Thing and maybe, yeah, that I found interesting, because I read, I'm reviewing a paper and they cited you andrea's and your highest approach to rely reliability. Um, and they mentioned in passing, or they cited you, because they thought that you could use this method also for delineating more than.
Passing time into what is going into reliability namely how does Pre processing? Like, how much variance is.
Attributed to Pre processing, and I saw this would actually be a very nice addition to the brain reliability map thing because they we often have this. Oh, should we Pre process this Ray or that way? And that we also add this as a condition into the ice model to decompose the passing of time. And, um.
Differences in Pre processing and look.
Like, what, how can we, uh, yeah, separate arrow variances into, uh, these 3 source variances into the sources of true variance um, Pre processing variance and passing of time.
Would be interesting, but we still have to, uh.
Yeah, and negotiate a meeting with, but actually, I think it's easiest to just drop by with with him instead of trying to get him to agree to a meeting.
I don't know. Yeah.


### "Andreas Brandmaier" [00:05:09.179-00:05:16.217]
That's a very nice idea, I think. And, um, it's.
Particularly nice because it, it makes you think about the data structure and sort of what measures are repeated measures and what measures are not repeated measures.
And because of course, the Pre processing is a repeated measures condition, whereas other things.
In some of the studies may not be may be conditions that are not repeated.
Within person's right? So basically, you could make a bigger point out of this. Yeah. Mm. Hmm. Yeah. So that's yeah.


### "Aaron Peikert" [00:10:41.879-00:10:54.149]
It's also interesting about what the inference goal is in general, like Mm hmm.
Is our reliability estimate? Should it be.
Time point 1 processing method 1.
Onto a time on 2 processing method too, because I think that is usually the inference that you have that, uh, researchers make a claim, or try to generalize to.
Yes, it should be working for other researchers and other people, it should be working for other preprocessing method and.
At some point as well I like repeating measures.
Yeah, but since, uh, has to do the work, he has to think about how you can exploit this idea, uh, without putting into much effort.
Um.
Yeah, just reminder next week, I think is the research.
Um, the Berlin science wreak thing, uh, is also.
I forgot when it is anyway. Um, this week, we also have to get together with pharma methods on Friday, um, on the methods, of course, get together formal methods, but methods from home University. Um, then Nicholas is not here, but he has HPC access now um, that.
Surprisingly easy to get a new it account and access.
And it took a week, then.
Yeah, makes me and also other pH.
No, we don't have any PhD students. Uh, yeah. Uh, but this PhD Navigator thing is, I think quite interesting. Um, I sat together with the people of the councils and Micah to think about. What do we need? What Teresa but what do PhD students need to do and.
In which order and we tried to come up with this checklist thing and we all agreed to interview researcher of PhD students. Yeah. The Institute, um.
And, yes, I wanted to interview, therefore, marks.
And Nicholas, at some point.
Then, um, yeah, these are all the housekeeping things and since, that was pretty fast, I had some like, more.
Discuss ish things. Uh, but is there some housekeeping that we need to discuss this week?
Okay, um, then there's no housekeeping to discuss and I can continue with the, uh, couple of things. So, 1st thing I think is I have been I spent, I think most of the last week on reading stuff, or maybe even the last 2 weeks, which was.
Amazingly interesting, um, I'm usually.
Not very good at researching literature. I think it's also a little bit, uh, depending on the topic that is quite hard to find the correct things. Like, even if I invest time to research literature, I don't find the correct stuff. So, what changed last week? Is that I was looking at the.
Uh, journals where we are with considering publishing, and I was just reading all the titles that they have ever published and then all the abstracts that were interesting. And then only the papers that rain and, uh, this was much more fruitful because I found a couple of really nice papers that.
Have not pound with keyword search um.
Yeah, and I don't think I would have because the titles, and even the abstracts, we're not super matching to what I had in mind. Uh, but then the papers turned out to be super relevant. Um, and so.
Yeah, for example, um, we used in 1 paper, the term, um, statistical relevancy condition, which is a standing time and philosophy of science, but psychologist reinvent the term apparently, and call it diagnostic. And so.
So, in the papers on this topic, on psychologists, you read diagnostic in the title, which.
Was for me completely unrelated for what I was searching for, but just mathematically.
Identically defined, uh, basically and, um, yeah, so some, um, yeah, that was just a lesson that I learned to sometimes dig deeper into, uh.
Do a less systematic search in the sense of not relying on keywords, but, uh, like snowballing. So, like, look who cited a paper that is relevant or what cited relevant paper, but also just going through a, and think what is interesting there. Um.
Because it's quite fast to go to 200 titles and to decide oh, no, this is not relevant to pick the 1 out of 200. that might be relevant from the title. Um.
Okay, um, I don't know I'm address. Do you have any recommendations on how to be more efficient about finding the right literature?


### "Andreas Brandmaier" [00:12:43.739-00:12:51.911]
I wish I had, but, I mean, I, I made the same observation that sometimes I, I thought I read most of the things about a topic and then exactly that happens when you described that there's a different name for the same thing.
And then you have a literature that dates back to 60 or 70 years, or whatever, and everything actually has already been said.
Right and it's easy to miss so I think, yeah, I think it's really have to what you describe. Right? Do the keyword search title search uh.
John is also talk to other people. That's that's sort of my.
Uh, my main source of of knowledge is just ask people, especially people who have been in the field for 20 years more than you have been.
And then they often know the literature and now the terms.
Right and then you have the, the additional problem that you go to a different field like economics Econometrics.
And they have been doing the same thing for decades and call it yet again differently.
And at some point where you have to stop, of course, and say, like, okay, this is.
Sort of what's known in this field and it can only research so far.
Yeah, but a, maybe the lesson particularly for your own writing is.
That it really matters what keywords you pick, because this is very often something I feel, you know, I'm.
I am not very motivated to come up with keywords because, I mean, it's a point where you've written this whole thing and you're kind of, you know, you want to submit it.
Get it off your desk and then it's easy to just dismiss this as an exercise. That's not very valuable. But, I mean, the lesson here is maybe that it's really is important that you pick.
Proper keywords that are not in your title and that are not in your abstract.
This makes a good keyword, I think.


### "Aaron Peikert" [00:14:20.459-00:14:39.325]
I think very good point in regards to keyboards that if they are already in the title and abstract.
There's little advantage of putting them as a keyword keyword as well. Um.
Then I got a very like, I was sometimes I'm really.
Surprised by how publishing works, because I got an email by nature human behavior, whether I want to submit.
A paper predicting natural disasters, because they think I'm an expert and predicting that stuff.
I didn't know that. It's like a part of the criticism that I, I'm a natural disaster, but really, how, how could they come up with this idea? And it's just because I have reviewed a couple of papers in the past, um, or started in the last couple of months, reviewing a couple of pain of them.
And now they write and I find that, like, pretty predatory and it's not.
I checked, it's not like it's not impossible. Like, it's not impersonating them. It's like the actual.
Associate editor of this channel from the official spring I email is asking me to submit a paper for a special issue and I find that.
Extremely strange. Why would they do that?
What I can't it's super weird.
Yeah, I mean, we are used to that from some publishers like that. I like walking around this whole special issue thing, but you saw that, like, these high impact channels wouldn't do such a thing. Um, yeah. Anyway.


### "Andreas Brandmaier" [00:17:02.249-00:17:09.984]
I mean, they are companies at the end of the day at the end of the day what they have to maximize revenue.
And this leads to very odd things and especially if these are sort of with the national.
Basically, international companies, um, with different branches, and they are just so big. I guess that the different sub journals are managed very differently. I think even if it's a nature Journal, which has, of course, a very high reputation in the field.
But I think there are many things wrong, especially with high impact journals.
Even if they don't do these predatory practices, they.
I think just the, the reviewers that they often pick.
It's, it's just outrageous, you know, I mean, I, I think I told you that I submitted this 1 paper with outreach to science and it actually was in the review process of science.
Um, and it was rejected among other things, of course, because 1 of the reviewers said.
That, you know, basically, why do we use statistics to make our point? Because.
Clearly the review, I can see that everything looks very differently in the 1 figure that we showed.
We show the data, it looks very different to what our model predicts. So, why we do need statistical modeling in the 1st place and that. It should. It's all bogus bullshit. Basically.
And this is the top tier journey that we have.
This is it's just very frustrating. I think.
And we appeal to the editor, making points about statistical modeling is important and then they didn't even get back to us.
And this is 1 of the many things that go wrong with these channels.
Apart from the whole criticism that of course, they, they basically pick.
I'm sorry, they basically pick.
Things that are sort of novel and interesting and exciting. And by this way, introducing a lot of bias into the field.
Right and sort of encouraged indirectly and all these kind of criticism. So I, I'm see, I think I got used to these kind of practices that I'm not even surprised.
And, I mean, in general, you get like, longer you are in this field, the more of these kind of emails you get.
And they get stranger and stranger I got this the other time I got this email I wasn't invited to a special issue on.
On the removal of forests, right? In an ecological Journal, because I published on decision trees in statistics.


### "Aaron Peikert" [00:17:09.984-00:17:21.244]
Okay, okay, but what is the I'm doing this, like, this kind of predatory behavior.


### "Andreas Brandmaier" [00:17:55.859-00:18:01.525]
Revenue outreach, they just basically want to maximize the impact so they try to publish as much as they can. And since they are journalists that don't print anymore.
They have virtually no costs. I mean, they have these are big publishing houses. They have the whole machinery working. They have these production offices anyway.
So, if they just add 1 more Journal, it doesn't cost them anything. Basically.
In the grand scheme of things, so they can afford to just.
Have new journals and then, I mean.
A John is successful if they publish a lot of stuff, right? Because then this.
Increases citation count, then you a check new office again and so forth. So.


### "Aaron Peikert" [00:22:49.679-00:23:09.679]
And they, that is 1 of the main criticism. And I think, uh, Max planning is 1 of the most depend on that regard that open times for the past decade has been mainly about open access.
Um, which means that, instead of pay per read, you pay per publish, um, which means the more like, nature wouldn't even care about.
Being cited or something, if enough people just publish there, they pay for public. So every paper that is published there, I think nature human behavior. It costs 7,000 euro to publish there.
So, if we would submit a paper, there it is 7,000 Euro. That is.
It's different for special issues, and probably they have like a discount because they invited you and stuff, but they earn money by publishing.
Each paper, um, and the criticism that marks blank, I think.
Like, they have become through open access a lot more profitable donors, um, which is, I think, often overlooked.
Uh, because at 1st, like, and it's the MO, most major 1, they was like, no, we don't do this kind of like paper publish. Um, but then some people adapted it and figure out that it's much more profitable, uh, than selling subscriptions. Um.
I think, um, it's just that there was more money everyone was expecting open signs will cost money. So they a lot of more budgets wide.
Including my, um, so they have an enormous amount of money that they allocated specifically to that, because they're like, oh, if we want to do things better, they cost more. Mm. Hmm. And so it was justified. And, uh, there's also this, um.
Appeal process through the European Union that you.
Talk to your representative about what you want. Um, and this is something that is very sellable where they can, where.
Someone who is not a scientist immediately understands why it's useful to say we want to make science accessible and then oh, and this is expensive and they just accepted and write it into a budget for European Union. Um, and so, for example, there was a huge lobbying effort. Um.
In for all the science funding that they, if something is funded by the European Union, and so forth has to be published, open access and this was.
Lobbied by not only open signed advocates, but also by publishing companies. Um, and for example, I think, uh.
Clear reasoning in 2010 for society was we have the money, we can outcompete people here because we can just pay our way through.
Um, and if you talk to next time, digital library, they even admits to that being a concern, uh, for them that they can reach scientific Excellency by not doing anything else, but pay out pay people. And that is also weird.
For example, the publishing costs, uh, for nature are the highest of them all. Um, but the cost of course, is not higher. Okay. In nature. It's a printed Journal. So, for the non printed, you still have this rank order is more expensive to publish in high impact on us. But the cost is not higher. So there's like, it's obvious that they are just skimming.
Money from this process a little bit. Mm. Hmm.
Yeah, why don't we, why are we on the topic, uh, on, uh, this? I have a interesting paper that I'm reviewing this. The same. Uh.
I talked about earlier and I'm not quite sure how to do.
A good peer review, because they do all the right things for all the wrong reasons. So they come to the correct conclusion and recommend the right things, but actually.
It is inverse. Even the title is wrong. So, the title is something about.
Uh, for but also try to, um.
Trading bias for variance is in the title, but the mechanism that they use.
Is actually they are trading by variance for bias.
Um, and now I'm, I'm like, it is very hard in, in written text to persuade someone that they have, like, a major logical flaw on what they're doing.
Yeah, and now I'm, I don't know quite how to how to behave, because, of course, I want this paper to be published because it's excellent and just because they swapped bias and variance. It doesn't change anything, but still, it's it's a major thing to swap the core argument. Um.


### "Andreas Brandmaier" [00:24:21.689-00:24:29.554]
Well, the good thing is that you are not in a position that you have to make the decision.
Right this is the editors job. This is the 1st thing to realize as a reviewer. It's not.
You who has to make a decision about whether this is publishable or not.
But it's about your opinion and I would write it. Exactly. As you just told it to us.
You tell them this is an excellent paper. It's an important contribution to the literature.
It makes very good points. Um, but.
Well, this sort of a reversal in the logic.
And, uh, you have the following suggestions maybe I mean, if you're a kind reviewer, you make constructive.
Points how they can change it. That's also not something a reviewer has to do. It's also okay. Just to point out where your thing.
Think things go wrong, but, I mean, if you thought about it for so long, you can even point them and make a suggestion on how you think.
Uh, this is fixed by changing the order in the title of the terms and I don't know.
Yeah, tell them that as a sort of a logical thought, even though the conclusion is correct and so forth and.
So this is, this is what's what's valuable both to the editor and to the, to the office, I think. Yeah.


### "Aaron Peikert" [00:25:10.319-00:25:15.121]
Yeah, I guess I'm, I'm struggling with being so clear why this is the case because of course buyers, various trade off it's a subtle issue and they don't apply it to a statistical modeling per se, but they apply it to science.
As a, as a learner, um, and so there is.
Yeah, and, uh, and I wonder how much effort I should put into providing a very clear explanation because at some point, I'm feeling like I'm writing then a paper for them. Not really of course. But like.
And it's intriguing, you know, I like to think about what is.
What are they doing wrong? Exactly. And why are they doing it? Um, but I'm just.


### "Andreas Brandmaier" [00:25:15.121-00:25:17.708]
Yeah, wondering how much time to invest in to.


### "Aaron Peikert" [00:25:17.708-00:25:19.885]
Why this is no.


### "Andreas Brandmaier" [00:25:49.499-00:25:53.806]
Understand, but, you know, the rule number 1 for kind reviewers like you are is you are not an author.
This is something you should tell yourself every 15 minutes of doing a review. You are not a CO author.
Right. So tell them.
Point them to the things that are wrong and make a sort of.
I mean, reason about this and make a make a reasonable statement. Why you think so?
Don't fix it for them. Yeah.


### "Aaron Peikert" [00:25:53.806-00:26:01.644]
Yeah, maybe he'll come from lunch we can discuss the exact bias variance problem because it's very intriguing. Uh.


### "Andreas Brandmaier" [00:26:07.289-00:26:11.206]
That would be nice, but unfortunately, we I have 2 sick kids and I'll stay home.
And I will only be here, like, next week again.


### "Aaron Peikert" [00:26:11.206-00:26:16.264]
That's sad not even Friday or Friday we put this with a group marks.


### "Andreas Brandmaier" [00:26:27.509-00:26:38.447]
On Friday, we could also discuss the max.
Yeah, but I'm, I'm, I'm gone anyway. I mean, my original plan was to leave for a holiday. This is why I can't join on Friday.
Anyway, so sorry to hear that either, I'm, I'll be on vacation or I'll be sick. I worked right.


### "Aaron Peikert" [00:26:57.569-00:27:07.516]
I I hope for the former.
Okay, um.
Yeah, with that I don't have anything else.
Okay, then, um, C around, um, and at latest next Wednesday, 1 on.


### "Maximilian Ernst" [00:27:12.329-00:27:17.039]
Evening writing most of you.
Okay.